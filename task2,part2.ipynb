{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "RLduXUOtC9ic"
   },
   "source": [
    "# **Sergei Bruchkus, task 2**\n",
    "Building a model which is capable of rappinng like someone famous\n",
    "(aka Grime na russkom)..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "2ku896UDCqvR"
   },
   "source": [
    "# ***Here is the second method of solution based mainly on language models***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 837
    },
    "colab_type": "code",
    "id": "D23shHki5_KR",
    "outputId": "853a7c99-a7b1-4570-d393-762cb681b445"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting lyricsgenius\n",
      "  Downloading https://files.pythonhosted.org/packages/4a/47/5aba67735bf3b7f2b1f4c1e5d1f9892050847e27e7fafdec14fc72d41bc1/lyricsgenius-1.8.2-py3-none-any.whl\n",
      "Requirement already satisfied: requests>=2.20.0 in /usr/local/lib/python3.6/dist-packages (from lyricsgenius) (2.21.0)\n",
      "Collecting beautifulsoup4==4.6.0\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/9e/d4/10f46e5cfac773e22707237bfcd51bbffeaf0a576b0a847ec7ab15bd7ace/beautifulsoup4-4.6.0-py3-none-any.whl (86kB)\n",
      "\u001b[K     |████████████████████████████████| 92kB 4.5MB/s \n",
      "\u001b[?25hRequirement already satisfied: idna<2.9,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests>=2.20.0->lyricsgenius) (2.8)\n",
      "Requirement already satisfied: urllib3<1.25,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests>=2.20.0->lyricsgenius) (1.24.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests>=2.20.0->lyricsgenius) (2020.4.5.1)\n",
      "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests>=2.20.0->lyricsgenius) (3.0.4)\n",
      "Installing collected packages: beautifulsoup4, lyricsgenius\n",
      "  Found existing installation: beautifulsoup4 4.6.3\n",
      "    Uninstalling beautifulsoup4-4.6.3:\n",
      "      Successfully uninstalled beautifulsoup4-4.6.3\n",
      "Successfully installed beautifulsoup4-4.6.0 lyricsgenius-1.8.2\n",
      "Collecting pip\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/54/0c/d01aa759fdc501a58f431eb594a17495f15b88da142ce14b5845662c13f3/pip-20.0.2-py2.py3-none-any.whl (1.4MB)\n",
      "\u001b[K     |████████████████████████████████| 1.4MB 5.0MB/s \n",
      "\u001b[?25hInstalling collected packages: pip\n",
      "  Found existing installation: pip 19.3.1\n",
      "    Uninstalling pip-19.3.1:\n",
      "      Successfully uninstalled pip-19.3.1\n",
      "Successfully installed pip-20.0.2\n",
      "Requirement already up-to-date: dill in /usr/local/lib/python3.6/dist-packages (0.3.1.1)\n",
      "Collecting nltk==3.5b1\n",
      "  Downloading nltk-3.5b1.zip (1.4 MB)\n",
      "\u001b[K     |████████████████████████████████| 1.4 MB 4.7 MB/s \n",
      "\u001b[?25hRequirement already satisfied, skipping upgrade: click in /usr/local/lib/python3.6/dist-packages (from nltk==3.5b1) (7.1.1)\n",
      "Requirement already satisfied, skipping upgrade: joblib in /usr/local/lib/python3.6/dist-packages (from nltk==3.5b1) (0.14.1)\n",
      "Requirement already satisfied, skipping upgrade: regex in /usr/local/lib/python3.6/dist-packages (from nltk==3.5b1) (2019.12.20)\n",
      "Requirement already satisfied, skipping upgrade: tqdm in /usr/local/lib/python3.6/dist-packages (from nltk==3.5b1) (4.38.0)\n",
      "Building wheels for collected packages: nltk\n",
      "  Building wheel for nltk (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
      "  Created wheel for nltk: filename=nltk-3.5b1-py3-none-any.whl size=1434692 sha256=4290f82083857143034d0ae96618448217f7a509902c1c1bc6909501b8f51973\n",
      "  Stored in directory: /root/.cache/pip/wheels/d3/86/25/c46dd9a7eced213ff414cc8266b44bb26e61f3f787d36d8dfc\n",
      "Successfully built nltk\n",
      "Installing collected packages: nltk\n",
      "  Attempting uninstall: nltk\n",
      "    Found existing installation: nltk 3.2.5\n",
      "    Uninstalling nltk-3.2.5:\n",
      "      Successfully uninstalled nltk-3.2.5\n",
      "Successfully installed nltk-3.5b1\n"
     ]
    },
    {
     "data": {
      "application/vnd.colab-display-data+json": {
       "pip_warning": {
        "packages": [
         "nltk"
        ]
       }
      }
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "!pip install lyricsgenius\n",
    "!pip install -U pip\n",
    "!pip install -U dill\n",
    "!pip install -U nltk==3.5b1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 68
    },
    "colab_type": "code",
    "id": "SD54wILBHBzP",
    "outputId": "9972447f-5b12-42d2-91df-aeead0dc27e3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
      "[nltk_data]   Unzipping tokenizers/punkt.zip.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 12,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('punkt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "2huXugIXfZNd"
   },
   "outputs": [],
   "source": [
    "#importing all the necessary libraries\n",
    "from nltk import word_tokenize\n",
    "from nltk import sent_tokenize\n",
    "from nltk import tokenize\n",
    "from nltk.tokenize import LineTokenizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from nltk.util import pad_sequence\n",
    "from nltk.util import bigrams\n",
    "from nltk.util import ngrams\n",
    "from nltk.util import everygrams\n",
    "from nltk.lm.preprocessing import pad_both_ends\n",
    "from nltk.lm.preprocessing import flatten\n",
    "from nltk.lm import MLE\n",
    "from nltk.lm import Laplace\n",
    "from nltk.lm import KneserNeyInterpolated\n",
    "from nltk.lm.preprocessing import padded_everygram_pipeline\n",
    "from nltk.tokenize.treebank import TreebankWordDetokenizer\n",
    "\n",
    "import lyricsgenius\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import nltk\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "cULWJubXfe2e",
    "outputId": "599070c6-6f77-4fcd-9fcf-7254218dbef0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Searching for songs by Oxxxymiron...\n",
      "\n",
      "Song 1: \"16 Bars Acapella\"\n",
      "Song 2: \"Afterparty (Demo)\"\n",
      "Song 3: \"AI Ogon\"\n",
      "Song 4: \"Amplify and simplify (Freestyle)\"\n",
      "Song 5: \"CCTV\"\n",
      "Song 6: \"Darkside\"\n",
      "Song 7: \"Freestyle #1\"\n",
      "Song 8: \"Ganz Promo Tune\"\n",
      "Song 9: \"Hangover\"\n",
      "Song 10: \"HPL\"\n",
      "Song 11: \"IMPERIVM\"\n",
      "Song 12: \"Intro\"\n",
      "Song 13: \"OXXXYMIRON\"\n",
      "Song 14: \"Russky Cockney\"\n",
      "Song 15: \"Shade 45 Freestyle (Идея)\"\n",
      "Song 16: \"Street Freestyle battle\"\n",
      "Song 17: \"Ultima Thule\"\n",
      "Song 18: \"Unreleased Track\"\n",
      "Song 19: \"Unreleased Track 2\"\n",
      "Song 20: \"Unreleased Track 3\"\n",
      "Song 21: \"Unreleased Track 4\"\n",
      "Song 22: \"XXX SHOP\"\n",
      "Song 23: \"Башня из слоновой кости (Ivory Tower)\"\n",
      "Song 24: \"Биполярочка (Bipolarochka)\"\n",
      "Song 25: \"Больше Бена (Bigga Than Ben)\"\n",
      "Song 26: \"В бульбуляторе (In the Bong)\"\n",
      "Song 27: \"В говне (In Shit)\"\n",
      "Song 28: \"В долгий путь (1 раунд 17ib) (On a Long Journey)\"\n",
      "Song 29: \"Ветер перемен (2 раунд 17ib) (The Wind of Change)\"\n",
      "Song 30: \"Вечный жид (Everlasting Jew)\"\n",
      "Song 31: \"Витязи словоблудия (Уховертка) (The Knights of Verbiage (Earwig))\"\n",
      "Song 32: \"В книге всё было по-другому (4 раунд 17ib) (The Book Had It Different)\"\n",
      "Song 33: \"Волапюк (Volapük)\"\n",
      "Song 34: \"Восточный Мордор (East Mordor)\"\n",
      "Song 35: \"Всего лишь писатель (Just a Writer)\"\n",
      "Song 36: \"В стране женщин (In the country of women)\"\n",
      "Song 37: \"«Где нас нет» (”On the Other Side”)\"\n",
      "Song 38: \"Город под подошвой (City Under the Sole)\"\n",
      "Song 39: \"Город под подошвой (GPP tour version)\"\n",
      "Song 40: \"Девочка Пиздец (Devochka Pizdets) (2011/2012 demo)\"\n",
      "Song 41: \"Девочка Пиздец (Fucked Up Girl)\"\n",
      "Song 42: \"Дело нескольких минут (3 раунд 17ib) (A Matter of Minutes)\"\n",
      "Song 43: \"День физкультурника (Athlete’s Day)\"\n",
      "Song 44: \"Детектор лжи (Lie Detector)\"\n",
      "Song 45: \"До зимы (Before Winter)\"\n",
      "Song 46: \"До сих пор MC (Still MC)\"\n",
      "Song 47: \"Жук в муравейнике (Beetle in an anthill)\"\n",
      "Song 48: \"Интро (Intro II)\"\n",
      "Song 49: \"Йети и дети (Yeti and children)\"\n",
      "Song 50: \"Каменный Век Русской Поэзии (Stone Age of Russian Poetry)\"\n",
      "Song 51: \"Кем ты стал? (What Had You Become?)\"\n",
      "Song 52: \"Колыбельная (Lullaby)\"\n",
      "Song 53: \"Крокодиловы слёзы (Crocodile tears)\"\n",
      "Song 54: \"Литература (Фристайл) (Literature (Freestyle))\"\n",
      "Song 55: \"Лондонград (OST Londongrad)\"\n",
      "Song 56: \"Лондон против всех (London Vs. Everyone)\"\n",
      "Song 57: \"Лондон против всех, ч. 2 (London Vs. Everyone, p. 2)\"\n",
      "Song 58: \"Мой менталитет (Oi Oi)\"\n",
      "Song 59: \"Накануне (On the Eve)\"\n",
      "Song 60: \"На куски (Demo) (In Pieces)\"\n",
      "Song 61: \"Неваляшка (Tumbler Toy)\"\n",
      "Song 62: \"Не говори ни слова (Ne govori ni slova)\"\n",
      "Song 63: \"Не от мира сего (Not of This World)\"\n",
      "Song 64: \"Не с начала (Not From the Beginning)\"\n",
      "Song 65: \"Нет связи (No connection)\"\n",
      "Song 66: \"Пародия на группу Centr freestyle\"\n",
      "Song 67: \"Переплетено (Interlaced)\"\n",
      "Song 68: \"Песенка Гремлина (Gremlin’s Song)\"\n",
      "Song 69: \"Песенка про Шахматиста (Song About a Chess Player)\"\n",
      "Song 70: \"«Полигон» (“Butts”)\"\n",
      "Song 71: \"Последний звонок (Last Call)\"\n",
      "Song 72: \"Привет со дна  (Hello from the Bottom)\"\n",
      "Song 73: \"Признаки Жизни (Signs of Life)\"\n",
      "Song 74: \"Пролив Дрейка (Drake Passage)\"\n",
      "Song 75: \"Раунд 1: 3030 год (Round 1: 3030 year)\"\n",
      "Song 76: \"Слово мэра (Mayor’s Word)\"\n",
      "Song 77: \"Спонтанное самовозгорание (Spontaneous Combustion)\"\n",
      "Song 78: \"Судьба моралиста (The fate of the moralist)\"\n",
      "Song 79: \"Тайные желания (Secret Desires)\"\n",
      "Song 80: \"Тентакли (Tentacles)\"\n",
      "Song 81: \"Три монолога (Three Monologues)\"\n",
      "Song 82: \"Хитиновый покров (Chitin Shell)\"\n",
      "Song 83: \"Ходят слухи (Hodyat sluhi)\"\n",
      "Song 84: \"Цифры и цвета (Numbers & colors)\"\n",
      "Song 85: \"Чёртово колесо (Chyortovo Koleso)\"\n",
      "Song 86: \"Шалом (Shalom)\"\n",
      "Song 87: \"Я Хейтер (I’m a Hater)\"\n",
      "Song 88: \"Ящик фокусника (Yaschik Fokusnika)\"\n",
      "Done. Found 88 songs.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "#here we search for all oxxxy songs, we got 88 songs\n",
    "genius = lyricsgenius.Genius(\"37_kPKwZgAEV2w8GjOYcuK-2c79H9YUx9PHkN_38aFDJa3Vdxzjveb7YDJ8TSCC1\")\n",
    "genius.remove_section_headers = True # Remove section headers - it came to be really important\n",
    "artist1 = genius.search_artist(\"Oxxxymiron\",  sort=\"title\")\n",
    "#print(artist1.songs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 68
    },
    "colab_type": "code",
    "id": "12TBjtrlcm9z",
    "outputId": "4b669f85-c881-494e-b053-d81710028bc0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Lyrics_Oxxxymiron.txt already exists. Overwrite?\n",
      "(y/n): y\n",
      "Wrote `Lyrics_Oxxxymiron.txt`\n"
     ]
    }
   ],
   "source": [
    "# create txt file with all the lyrics\n",
    "artist1.save_lyrics(extension='txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "8OS5Uhfjc-aH",
    "outputId": "aa323c67-a6f3-4268-abd4-343d3f627d26"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<_io.TextIOWrapper name='Lyrics_Oxxxymiron.txt' mode='r' encoding='UTF-8'>\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "\n",
    "#we open the file and check the format\n",
    "lyricsoxxxy = open(\"Lyrics_Oxxxymiron.txt\",\"r\")\n",
    "print (lyricsoxxxy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "PIUL2shyxM0W"
   },
   "outputs": [],
   "source": [
    "# we prepare tha data to make it appropriate ny using lower case and tokenization\n",
    "token_text = [list(map(str.lower, word_tokenize(sent))) \n",
    "                  for sent in lyricsoxxxy]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "aZsBp0KUWdKj"
   },
   "outputs": [],
   "source": [
    "# the same with the first part of this task - here we define a special function, we build a part with 5 lines \n",
    "def generate_rap (model, num_lines = 5, num_words_in_line = 10, random_seed = 4773):\n",
    "  for i in range(num_lines):\n",
    "    content = []\n",
    "    for token in model.generate(num_words_in_line, random_seed=random_seed+i):\n",
    "      if token == '<s>':\n",
    "        continue\n",
    "      if token == '</s>':\n",
    "        break #the symbol for the end\n",
    "      content.append(token)\n",
    "    content = TreebankWordDetokenizer().detokenize(content)\n",
    "    if bool(content):\n",
    "      i = 0\n",
    "      while not content[i].isalpha():\n",
    "          i += 1\n",
    "          if i > len(content)-1:\n",
    "            break\n",
    "      print(content[i:].capitalize())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "NXFpQ9hWSP1f"
   },
   "outputs": [],
   "source": [
    "#split the data on training and test samples\n",
    "train, test = train_test_split(token_text, test_size=0.2, random_state=4773)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "OiiOqekqdA3k"
   },
   "outputs": [],
   "source": [
    "#we apply three different models\n",
    "\n",
    "#firstly, we apply models based on unigramms\n",
    "\n",
    "model1 = MLE(1) #maximum likelyhood estmation, we evaluate the probability of the next word based on the prior\n",
    "train_data, padded_sents = padded_everygram_pipeline(1, train)\n",
    "model1.fit(train_data, padded_sents)\n",
    "\n",
    "model2 = Laplace(1) #the one we had a look atm a methof useful in cases when we have zero probability of meeting some words\n",
    "train_data1, padded_sents1 = padded_everygram_pipeline(1, train)\n",
    "model2.fit(train_data1, padded_sents1)\n",
    "\n",
    "model3 = KneserNeyInterpolated(1) #Interpolated version of Kneser-Ney smoothing\n",
    "train_data2, padded_sents2 = padded_everygram_pipeline(1, train)\n",
    "model3.fit(train_data2, padded_sents2)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "kr4f8hGjJ7Gk"
   },
   "outputs": [],
   "source": [
    "from nltk.tokenize.treebank import TreebankWordDetokenizer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 102
    },
    "colab_type": "code",
    "id": "IJRYwAhYdTLO",
    "outputId": "bc06835c-4140-4e36-ed36-0539342857f3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "В! стуле но меня так ,?\n",
      "Оплеухи, здесь скачаешь\"порох друзья ведь что хоккеист\n",
      "Измени к даже your, уверены и закончил )\n",
      "Доим похлеще свою витает и применяли быстро это все тоже\n",
      "Но на карикатурах улицам какого нет голубого . — машина\n"
     ]
    }
   ],
   "source": [
    "generate_rap(model1, random_seed = 4773)\n",
    "#the fact of combining russian and english lyrics is okay, generally"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 102
    },
    "colab_type": "code",
    "id": "3IAiqiz_zRtl",
    "outputId": "9d705ae5-037a-4080-b915-66de26da3a53"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Верну! сто осадки мог схваткам, m\n",
      "Переварю, и сколько (привкусом жук всего чистую франциск\n",
      "I калининграде клитор дом бег . у каждый и *\n",
      "Ждёт причитаешь себя выведи из пророс вдаль экосистем глазах тихой\n",
      "Она нарочно крики уж кочевал облысел дело download қотақбас мне\n"
     ]
    }
   ],
   "source": [
    "generate_rap(model2, random_seed = 4773)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 102
    },
    "colab_type": "code",
    "id": "A_uZkxb31SiN",
    "outputId": "444a6dd3-32d3-472d-c559-946317850b22"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Russia белой делегат're сраный поехали ниц стеклом ау быстрый\n",
      "Порою over кукол словаря aмур пьянство кладу друзьями хаджеводокгхида унесу\n",
      "Бугор марк месте иносказательно выбито бабулек трэшак лучше крекеры buddy\n",
      "Кашель разбегу симоны ересиарх лев распадаются девкам цепь жужжит таляляляля\n",
      "Подписать островной мораль тьме моисея победы золотая бонзам эдика низы\n"
     ]
    }
   ],
   "source": [
    "generate_rap(model3, random_seed = 4773)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "juGuNINcJeiq"
   },
   "outputs": [],
   "source": [
    "test_data1,_ = padded_everygram_pipeline(1, test)\n",
    "#to test the models on separated in the beginning test sample "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "BFEbKih1JgXP"
   },
   "outputs": [],
   "source": [
    "test_gen1 = []\n",
    "\n",
    "for line in test_data1:\n",
    "  test_gen1.extend(line)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 68
    },
    "colab_type": "code",
    "id": "H8nXLwZcJkYs",
    "outputId": "25622f21-cfe6-4bc0-eb1d-31ad814a2b69"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Perplexity for unigram MLE model is: inf\n",
      "Perplexity for unigram Laplace model is: 1625.375745453456\n",
      "Perplexity for unigram KneserNeyInterpolated model is: 9939.999999987811\n"
     ]
    }
   ],
   "source": [
    "print('Perplexity for unigram MLE model is: {}'.format(model1.perplexity(test_gen1)))\n",
    "print('Perplexity for unigram Laplace model is: {}'.format(model2.perplexity(test_gen1)))\n",
    "print('Perplexity for unigram KneserNeyInterpolated model is: {}'.format(model3.perplexity(test_gen1)))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "uB1jLQdtXYRo"
   },
   "source": [
    "If we judge by perplexity and compare the models, we can say that the first one show a way worse results compared to Laplace and KnesserNeyInterpolated (since perplexity is innfinity)\n",
    "Also, here, when we use unigrams, Laplace smoothinng is more effective (more probable lyrics on test sample) than KneserNeyInterpolated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "KXQQE7cf-NGQ"
   },
   "outputs": [],
   "source": [
    "#the same using bigrams, therefore we expect to get a something more likely to be a real way of words sequences by oxxxymiron\n",
    "model4 = MLE(2)\n",
    "train_data3, padded_sents3 = padded_everygram_pipeline(2, train)\n",
    "model4.fit(train_data3, padded_sents3)\n",
    "\n",
    "model5 = KneserNeyInterpolated(2)\n",
    "train_data4, padded_sents4 = padded_everygram_pipeline(2, train)\n",
    "model5.fit(train_data4, padded_sents4)\n",
    "\n",
    "model6 = Laplace(2)\n",
    "train_data5, padded_sents5 = padded_everygram_pipeline(2, train)\n",
    "model6.fit(train_data5, padded_sents5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 85
    },
    "colab_type": "code",
    "id": "ONhtg1qUCCB8",
    "outputId": "e6e11c92-65c3-4d8c-8477-2c282d16412f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Брат ,\n",
      "На базаре продаётся предсказание кассандры\n",
      "Бабана пишут такие modern talking (а я жопу рвать\n",
      "Мне не матерится, мимо икон\n"
     ]
    }
   ],
   "source": [
    "generate_rap(model4, random_seed = 4773)\n",
    "#hear i iunderstood that should have removed headers annd now i start from the beginning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 102
    },
    "colab_type": "code",
    "id": "ziHfH08mCCCE",
    "outputId": "0036cf49-0304-4894-bd79-eebd0df91935"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Runnin' you'll tec-9 when i ’ m a\n",
      "Порочишь её в сердце, само собою, экскюз ми\n",
      "Бу ...\n",
      "Кацапов, тебе восемь лет пролетело, я жопу рвать\n",
      "Подписан на меня так легко-оу уо-о\n"
     ]
    }
   ],
   "source": [
    "generate_rap(model5, random_seed = 4773)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "yyd5WAOrIlfw"
   },
   "source": [
    "It's pretty interesting that the previous block starts with english word and as a result, the whole string of the lyrics is English (since it's more likely than English word is followed by another english word).\n",
    "Also I have no idea why phrase \"zhopu rvat'\" appeared twice here.\n",
    "Also, for some reason we got 4 lines running MLE model and Laplace. Probably it's due to tehnical problems while running code and such a long time needed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 85
    },
    "colab_type": "code",
    "id": "dyTFsaCUC4s3",
    "outputId": "0750b935-8e70-47b0-8b62-24facc9a2c42"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Больше дел, тощий стебель\n",
      "Нелепые лохи недовольны всегда (пау!\n",
      "Венерических болезней\n",
      "Напас!\n"
     ]
    }
   ],
   "source": [
    "generate_rap(model6, random_seed = 4773)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "1IDFucw2c3t8"
   },
   "source": [
    "\n",
    "\n",
    "```\n",
    "For some reason, here we have pretty strange lyrics here...```\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "-QK2luAiKR5U"
   },
   "outputs": [],
   "source": [
    "test_data2,_ = padded_everygram_pipeline(2, test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "DAHhJQTOKR_V"
   },
   "outputs": [],
   "source": [
    "test_gen2 = []\n",
    "\n",
    "for line in test_data2:\n",
    "  test_gen2.extend(line)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 68
    },
    "colab_type": "code",
    "id": "uA-IJmB9KSGp",
    "outputId": "8daf21d1-1ef2-40a2-e5f0-6e3c93b5b6d6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Perplexity for unigram MLE model is: inf\n",
      "Perplexity for unigram KneserNeyInterpolated model is: 4379.608163733989\n",
      "Perplexity for unigram Laplace model is: 1597.378902532775\n"
     ]
    }
   ],
   "source": [
    "print('Perplexity for unigram MLE model is: {}'.format(model4.perplexity(test_gen2)))\n",
    "print('Perplexity for unigram KneserNeyInterpolated model is: {}'.format(model5.perplexity(test_gen2)))\n",
    "print('Perplexity for unigram Laplace model is: {}'.format(model6.perplexity(test_gen2)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "H3TUD0W_Ytgo"
   },
   "source": [
    "Again, judging by perplexity, MLE model performs very bad and there's almost zero chance to get some likely lyrics when we test the data.\n",
    "Laplace performance is still better than one my KnesserNeyInterpolation, even with bigrams."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "kzvVR2BsIjR9"
   },
   "outputs": [],
   "source": [
    "#trigrams implementation, now the texts should be even more coherent annd logic\n",
    "model7 = MLE(3)\n",
    "train_data6, padded_sents6 = padded_everygram_pipeline(3, train)\n",
    "model7.fit(train_data6, padded_sents6)\n",
    "\n",
    "model8 = Laplace(3)\n",
    "train_data7, padded_sents7 = padded_everygram_pipeline(3, train)\n",
    "model8.fit(train_data7, padded_sents7)\n",
    "\n",
    "model9 = KneserNeyInterpolated(3)\n",
    "train_data8, padded_sents8 = padded_everygram_pipeline(3, train)\n",
    "model9.fit(train_data8, padded_sents8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 85
    },
    "colab_type": "code",
    "id": "vCjiwjR_Ijd0",
    "outputId": "119388ae-8708-4b04-9345-0c0f6f5b5b73"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Брат, как темно\n",
      "Котом и некрономикон\n",
      "Когда я ещё был не в тот век ,\n",
      "Йе )\n"
     ]
    }
   ],
   "source": [
    "generate_rap(model7, random_seed = 4773)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "rfiEx3sudQDT"
   },
   "source": [
    "we even have some rhyme here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 85
    },
    "colab_type": "code",
    "id": "o63zlJF2ItOP",
    "outputId": "e93e8cec-b0c4-4cc4-a7b2-ba9569c98e46"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Больше дев, не проводи большой обыск\n",
      "Моей головой круглый неон — это кал, одна пуля\n",
      "Gimme some money now!\n",
      "Ложь не яд\n"
     ]
    }
   ],
   "source": [
    "generate_rap(model8, random_seed = 4773)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 102
    },
    "colab_type": "code",
    "id": "ZVjj5YeRIjcF",
    "outputId": "b4775532-8938-4932-ecdf-e2fa1e37b995"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Runnin' you can ’ t kill me, i\n",
      "Порочишь её криками``saint-p, man ''\n",
      "Бу...пере пуроста\n",
      "Кацапов, хачей и для русаков\n",
      "Подписан на рип . клеил чик, делал биз\n"
     ]
    }
   ],
   "source": [
    "generate_rap(model9, random_seed = 4773)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ASryVQeqZbFD"
   },
   "source": [
    "The textes we get have a lot of common with real texts of this rapper, since with use the probabilities of having three words in a row."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "EUR8AQPIKp8J"
   },
   "outputs": [],
   "source": [
    "test_data3,_ = padded_everygram_pipeline(3, test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ph0wym60KkX1"
   },
   "outputs": [],
   "source": [
    "test_gen3 = []\n",
    "\n",
    "for line in test_data3:\n",
    "  test_gen3.extend(line)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 68
    },
    "colab_type": "code",
    "id": "aox9QLkgKkbb",
    "outputId": "16495573-f45a-4a1e-d3c1-c216eb5306be"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Perplexity for unigram MLE model is: inf\n",
      "Perplexity for unigram Laplace model is: 1170.6233617271685\n",
      "Perplexity for unigram KneserNeyInterpolated model is: 1849.517337207427\n"
     ]
    }
   ],
   "source": [
    "print('Perplexity for unigram MLE model is: {}'.format(model7.perplexity(test_gen3)))\n",
    "print('Perplexity for unigram Laplace model is: {}'.format(model8.perplexity(test_gen3)))\n",
    "print('Perplexity for unigram KneserNeyInterpolated model is: {}'.format(model9.perplexity(test_gen3)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "sPK4FZJBaKEy"
   },
   "source": [
    "Laplace is still the best option, even though KneserNeyInterpolation is pretty close to it."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "nogIs1YCYlEp"
   },
   "source": [
    "**Here we'll try to add some other russian rap artist to this collection to ennlarge the vocabulary.** \n",
    "\n",
    "We would decide on the artist based on some vocabulary similarities with oxxxymiron (from some personal experience)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "jC7Uq0PwKkew",
    "outputId": "4d64d459-0cff-4847-b309-77537ff18e9d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Searching for songs by Хаски...\n",
      "\n",
      "Changing artist name to 'Хаски (Husky)'\n",
      "Song 1: \"Ай (Ai)\"\n",
      "Song 2: \"Аллилуйя (Hallelujah)\"\n",
      "Song 3: \"Бит шатает голову (Beat Shakes The Head)\"\n",
      "Song 4: \"Бэнг Бэнг (Bang Bang)\"\n",
      "Song 5: \"Все псы попадают в рай (All Dogs Go To Heaven)\"\n",
      "Song 6: \"Голубка (Dove)\"\n",
      "Song 7: \"Господин Собака (Mr. Dog)\"\n",
      "Song 8: \"Детка-Голливуд (Baby-Hollywood)\"\n",
      "Song 9: \"Дурачок (Fool)\"\n",
      "Song 10: \"Животворящий Флоу (Vital Flow)\"\n",
      "Song 11: \"Заново (Once Again)\"\n",
      "Song 12: \"Иисус (Jesus)\"\n",
      "Song 13: \"Иуда (Judas)\"\n",
      "Song 14: \"Карлсон (Carlson)\"\n",
      "Song 15: \"Колдунья(Witch)\"\n",
      "Song 16: \"Космолёт (Space Shuttle)\"\n",
      "Song 17: \"Крот ’17 (Mole 17)\"\n",
      "Song 18: \"Крот (Mole)\"\n",
      "Song 19: \"Люцифер (Lucifer)\"\n",
      "Song 20: \"Мармелад (Marmalade)\"\n",
      "Song 21: \"Моим людям (To My People)\"\n",
      "Song 22: \"Мультики (Cartoons)\"\n",
      "Song 23: \"Недо(бо)-человек\"\n",
      "Song 24: \"Отопление (Heating)\"\n",
      "Song 25: \"Панелька (Panel House)\"\n",
      "Song 26: \"Пироман (Pyromaniac)\"\n",
      "Song 27: \"Пироман ’17 (Pyromaniac)\"\n",
      "Song 28: \"Поэма о Родине (Poem About Motherland)\"\n",
      "Song 29: \"Пуля-дура (Stupid Bullet)\"\n",
      "Song 30: \"Седьмое октября (October 7th)\"\n",
      "Song 31: \"Седьмое октября (October 7th) (Re-Work)\"\n",
      "Song 32: \"Сибирская язва (Anthrax)\"\n",
      "\"Скит/Розовое вино (Skit/Pink Wine)\" is not valid. Skipping.\n",
      "Song 33: \"Смотрящий (Watcher)\"\n",
      "Song 34: \"Собачий вальс (Dog’s Waltz)\"\n",
      "Song 35: \"Собачья жизнь (Dog’s life)\"\n",
      "Song 36: \"Солдат (Soldier)\"\n",
      "Song 37: \"Список коллабораций (Collaboration List)\"\n",
      "Song 38: \"Тайга (Taiga)\"\n",
      "Song 39: \"Тараканий бог (Cockroaches God)\"\n",
      "Song 40: \"Тараканий бог (Cockroaches God) [Live]\"\n",
      "Song 41: \"Убить Рэпера (Kill The Rapper)\"\n",
      "Song 42: \"Фюрер (Fuhrer)\"\n",
      "Song 43: \"Хозяйка (Proprietress)\"\n",
      "Song 44: \"Человек в Интернете  (The Man On The Internet)\"\n",
      "Song 45: \"Черным-черно (Black)\"\n",
      "Song 46: \"Черным-черно/Мне похуй (Black-black/I Don’t Give A Fuck)\"\n",
      "Done. Found 46 songs.\n",
      "Searching for songs by Markul...\n",
      "\n",
      "Changing artist name to 'MARKUL'\n",
      "Song 1: \"25\"\n",
      "Song 2: \"B.I.D\"\n",
      "Song 3: \"BLUES\"\n",
      "Song 4: \"Fata Morgana\"\n",
      "\"FILES [Tracklist + Album Art]\" is not valid. Skipping.\n",
      "Song 5: \"Flexin\"\n",
      "Song 6: \"MBBIH\"\n",
      "Song 7: \"Moulin Rouge\"\n",
      "Song 8: \"Russky Roadman*\"\n",
      "Song 9: \"Slipknot\"\n",
      "Song 10: \"Untitled Collaboration\"\n",
      "Song 11: \"Wo Wo Wo\"\n",
      "Song 12: \"Zloi Part (Intro)\"\n",
      "Song 13: \"Адаптирован (Adaptirovan)\"\n",
      "Song 14: \"Атлантида (Atlantis)\"\n",
      "Song 15: \"Без тебя (Without You)\"\n",
      "Song 16: \"Больше бед (More troubles)\"\n",
      "Song 17: \"В тихом омуте (V Tihom Omute)\"\n",
      "Song 18: \"Деньги на ветер (Money Down the Drain)\"\n",
      "Song 19: \"Другой Маршрут (Another Route)\"\n",
      "Song 20: \"Компас (Compass)\"\n",
      "Song 21: \"Корабли в бутылках (Ships in Bottles)\"\n",
      "Song 22: \"Крэк I\"\n",
      "Song 23: \"Леброн (Lebron)\"\n",
      "Song 24: \"Мало добра (Malo Dobra)\"\n",
      "Song 25: \"Миражи (Mirages)\"\n",
      "Song 26: \"На виду (Na vidu)\"\n",
      "Song 27: \"На горизонте (Na gorizonte)\"\n",
      "Song 28: \"Не всем (Ne vsem)\"\n",
      "Song 29: \"Не до сна (Ne do sna)\"\n",
      "Song 30: \"Не зря (Not In Vain)\"\n",
      "Song 31: \"Отрицание (Negation)\"\n",
      "Song 32: \"Последний билет (Last Ticket)\"\n",
      "Song 33: \"Прорвёмся (Will Break Through)\"\n",
      "Song 34: \"Прямой эфир (Live)\"\n",
      "Song 35: \"Пьяный DJ\"\n",
      "Song 36: \"Серпантин (Serpentine)\"\n",
      "Song 37: \"Скалы (Rocks)\"\n",
      "Song 38: \"Спрут (Sprut)\"\n",
      "Song 39: \"Сухим из воды (Suhim iz vody)\"\n",
      "Song 40: \"Худший друг (Worst Friend)\"\n",
      "Done. Found 40 songs.\n",
      "Searching for songs by Johnyboy...\n",
      "\n",
      "Song 1: \"Bassboosted\"\n",
      "Song 2: \"B лапах дракона (In the clutches of a dragon)\"\n",
      "Song 3: \"Hoodie\"\n",
      "Song 4: \"Intro\"\n",
      "Song 5: \"MONEY BUS\"\n",
      "Song 6: \"PVTHXLXGY\"\n",
      "Song 7: \"VVV\"\n",
      "Song 8: \"XXL FRESHMEN DISS (Соня Мармеладова Challenge)\"\n",
      "Song 9: \"Zero\"\n",
      "Song 10: \"Акулы-пантеры (Sharks-Panthers)\"\n",
      "Song 11: \"Алкоголь и дым (Alchohol and smoke)\"\n",
      "Song 12: \"Американская мечта (American Dream)\"\n",
      "Song 13: \"Близость — максимум (Intimate — Maximum)\"\n",
      "Song 14: \"Ванна полная льда (VPL)\"\n",
      "Song 15: \"В долгий путь (1 раунд 17ib) (On a Long Journey)\"\n",
      "Song 16: \"Ветер перемен (2 раунд 17ib) (The Wind of Change)\"\n",
      "Song 17: \"Вечно горящий дом (VGD)\"\n",
      "Song 18: \"В книге всё было по-другому (4 раунд 17ib) (The Book Had It Different)\"\n",
      "Song 19: \"Влечение (Appetence)\"\n",
      "Song 20: \"В неожиданном ракурсе (5 раунд 17ib) (In an unexpected perspective)\"\n",
      "Song 21: \"В памяти мира (In the memory of the world)\"\n",
      "Song 22: \"Всё пиздато Ч.2. (Vol.2)\"\n",
      "Song 23: \"Гимн пропущенных вечеринок (Missed Parties Anthem)\"\n",
      "Song 24: \"Годы пройдут не зря (GPNZ)\"\n",
      "Song 25: \"Голыми руками (Naked Hands)\"\n",
      "Song 26: \"Два албанца (Two Albanians)\"\n",
      "Song 27: \"Девять миллиардов (Nine Billion)\"\n",
      "Song 28: \"Дело нескольких минут (3 раунд 17ib) (A matter of minutes)\"\n",
      "Song 29: \"Демоны (The Demons)\"\n",
      "Song 30: \"День мучителя (Torturer’s Day)\"\n",
      "Song 31: \"День плохого парня (Bad Guys’ Day)\"\n",
      "Song 32: \"До первого шторма (Before the first storm)\"\n",
      "Song 33: \"Завтра больше не будет (ZBNB)\"\n",
      "Song 34: \"Звездопад столетия (Starfall century)\"\n",
      "Song 35: \"Значит всё 3,14здато\"\n",
      "Song 36: \"Зреет потоп (Maturing the flood)\"\n",
      "Song 37: \"Камеры (Camers)\"\n",
      "Song 38: \"Ким Кардашьян (Kim Kardashian)\"\n",
      "Song 39: \"Когда мы взлетаем (When We Take Off)\"\n",
      "Song 40: \"Купи новый Бентли (Buy A New Bentley)\"\n",
      "Song 41: \"Лёд и пламя (Ice & Fire)\"\n",
      "Song 42: \"Любой ценой (At any cost)\"\n",
      "Song 43: \"Метамфетамир (Metamfetamir)\"\n",
      "Song 44: \"Мой первый миллион (My First Million)\"\n",
      "Song 45: \"Моя книга грехов (My Book Of Sins)\"\n",
      "Song 46: \"Моя комната пуста\"\n",
      "Song 47: \"Мы смогли (We Were Able)\"\n",
      "Song 48: \"На всю башку (In the Head)\"\n",
      "Song 49: \"Нам Покорится Небо (We Will Defeat the Sky)\"\n",
      "Song 50: \"Напоминай мне (Remind Me)\"\n",
      "\n",
      "Reached user-specified song limit (50).\n",
      "Done. Found 50 songs.\n",
      "Searching for songs by Oxxxymiron...\n",
      "\n",
      "Song 1: \"16 Bars Acapella\"\n",
      "Song 2: \"Afterparty (Demo)\"\n",
      "Song 3: \"AI Ogon\"\n",
      "Song 4: \"Amplify and simplify (Freestyle)\"\n",
      "Song 5: \"CCTV\"\n",
      "Song 6: \"Darkside\"\n",
      "Song 7: \"Freestyle #1\"\n",
      "Song 8: \"Ganz Promo Tune\"\n",
      "Song 9: \"Hangover\"\n",
      "Song 10: \"HPL\"\n",
      "Song 11: \"IMPERIVM\"\n",
      "Song 12: \"Intro\"\n",
      "Song 13: \"OXXXYMIRON\"\n",
      "Song 14: \"Russky Cockney\"\n",
      "Song 15: \"Shade 45 Freestyle (Идея)\"\n",
      "Song 16: \"Street Freestyle battle\"\n",
      "Song 17: \"Ultima Thule\"\n",
      "Song 18: \"Unreleased Track\"\n",
      "Song 19: \"Unreleased Track 2\"\n",
      "Song 20: \"Unreleased Track 3\"\n",
      "Song 21: \"Unreleased Track 4\"\n",
      "Song 22: \"XXX SHOP\"\n",
      "Song 23: \"Башня из слоновой кости (Ivory Tower)\"\n",
      "Song 24: \"Биполярочка (Bipolarochka)\"\n",
      "Song 25: \"Больше Бена (Bigga Than Ben)\"\n",
      "Song 26: \"В бульбуляторе (In the Bong)\"\n",
      "Song 27: \"В говне (In Shit)\"\n",
      "Song 28: \"В долгий путь (1 раунд 17ib) (On a Long Journey)\"\n",
      "Song 29: \"Ветер перемен (2 раунд 17ib) (The Wind of Change)\"\n",
      "Song 30: \"Вечный жид (Everlasting Jew)\"\n",
      "Song 31: \"Витязи словоблудия (Уховертка) (The Knights of Verbiage (Earwig))\"\n",
      "Song 32: \"В книге всё было по-другому (4 раунд 17ib) (The Book Had It Different)\"\n",
      "Song 33: \"Волапюк (Volapük)\"\n",
      "Song 34: \"Восточный Мордор (East Mordor)\"\n",
      "Song 35: \"Всего лишь писатель (Just a Writer)\"\n",
      "Song 36: \"В стране женщин (In the country of women)\"\n",
      "Song 37: \"«Где нас нет» (”On the Other Side”)\"\n",
      "Song 38: \"Город под подошвой (City Under the Sole)\"\n",
      "Song 39: \"Город под подошвой (GPP tour version)\"\n",
      "Song 40: \"Девочка Пиздец (Devochka Pizdets) (2011/2012 demo)\"\n",
      "Song 41: \"Девочка Пиздец (Fucked Up Girl)\"\n",
      "Song 42: \"Дело нескольких минут (3 раунд 17ib) (A Matter of Minutes)\"\n",
      "Song 43: \"День физкультурника (Athlete’s Day)\"\n",
      "Song 44: \"Детектор лжи (Lie Detector)\"\n",
      "Song 45: \"До зимы (Before Winter)\"\n",
      "Song 46: \"До сих пор MC (Still MC)\"\n",
      "Song 47: \"Жук в муравейнике (Beetle in an anthill)\"\n",
      "Song 48: \"Интро (Intro II)\"\n",
      "Song 49: \"Йети и дети (Yeti and children)\"\n",
      "Song 50: \"Каменный Век Русской Поэзии (Stone Age of Russian Poetry)\"\n",
      "\n",
      "Reached user-specified song limit (50).\n",
      "Done. Found 50 songs.\n"
     ]
    }
   ],
   "source": [
    "genius = lyricsgenius.Genius(\"37_kPKwZgAEV2w8GjOYcuK-2c79H9YUx9PHkN_38aFDJa3Vdxzjveb7YDJ8TSCC1\")\n",
    "genius.remove_section_headers = True # Remove section headers\n",
    "#add other artists\n",
    "Hasky = genius.search_artist(\"Хаски\", max_songs=50, sort=\"title\")\n",
    "Markul = genius.search_artist(\"Markul\", max_songs=50, sort=\"title\")\n",
    "Johny = genius.search_artist(\"Johnyboy\", max_songs=50, sort=\"title\")\n",
    "artist1 = genius.search_artist(\"Oxxxymiron\", max_songs=50, sort=\"title\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 85
    },
    "colab_type": "code",
    "id": "jZf-XIZhM5Yj",
    "outputId": "a398b42f-39e1-4940-8469-e7ab3c830dfd"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wrote `Lyrics_ХаскиHusky.txt`\n",
      "Wrote `Lyrics_Oxxxymiron.txt`\n",
      "Wrote `Lyrics_MARKUL.txt`\n",
      "Wrote `Lyrics_Johnyboy.txt`\n"
     ]
    }
   ],
   "source": [
    "Hasky.save_lyrics(extension='txt')\n",
    "artist1.save_lyrics(extension='txt')\n",
    "Markul.save_lyrics(extension='txt')\n",
    "Johny.save_lyrics(extension='txt')\n",
    "#like we did with oxxxymiron lyrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "5-uKtA8_M5fb"
   },
   "outputs": [],
   "source": [
    "Hasky_lyr= open(\"Lyrics_ХаскиHusky.txt\",\"r\")\n",
    "Mark_lyr = open(\"Lyrics_MARKUL.txt\",\"r\")\n",
    "Johny_lyr = open(\"Lyrics_Johnyboy.txt\",\"r\")\n",
    "lyricsoxxxy = open(\"Lyrics_Oxxxymiron.txt\",\"r\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "w73V_5CTM5il"
   },
   "outputs": [],
   "source": [
    "\n",
    "Hasky_tokenized = [list(map(str.lower, word_tokenize(sent))) \n",
    "                  for sent in Hasky_lyr]\n",
    "Mark_tokenized = [list(map(str.lower, word_tokenize(sent))) \n",
    "                  for sent in Mark_lyr]\n",
    "Johny_tokenized = [list(map(str.lower, word_tokenize(sent))) \n",
    "                  for sent in Johny_lyr]\n",
    "token_text = [list(map(str.lower, word_tokenize(sent))) \n",
    "                  for sent in lyricsoxxxy]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "1OIPzTUpM5lv",
    "outputId": "fc83696f-7021-4b75-d200-1ad25664846b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11695\n"
     ]
    }
   ],
   "source": [
    "lyricst = [] #for storing the whole corpus of lyrics\n",
    "lyricst.extend(token_text)\n",
    "lyricst.extend(Hasky_tokenized)\n",
    "lyricst.extend(Mark_tokenized)\n",
    "lyricst.extend(Johny_tokenized)\n",
    "print(len(lyricst))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "wNzM4R0vvTWE"
   },
   "source": [
    "impressive..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "cTFcNW93M5qn"
   },
   "outputs": [],
   "source": [
    "train, test = train_test_split(lyricst, test_size=0.2, random_state=1212)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "_pYZn0tfM5om"
   },
   "outputs": [],
   "source": [
    "#we use the same algorithm with 3 models, and uni-, bi- and thigrams\n",
    "#firstly, unnigrms\n",
    "model1 = MLE(1)\n",
    "train_data, padded_sents = padded_everygram_pipeline(1, train)\n",
    "model1.fit(train_data, padded_sents)\n",
    "\n",
    "model2 = Laplace(1)\n",
    "train_data1, padded_sents1 = padded_everygram_pipeline(1, train)\n",
    "model2.fit(train_data1, padded_sents1)\n",
    "\n",
    "model3 = KneserNeyInterpolated(1)\n",
    "train_data2, padded_sents2 = padded_everygram_pipeline(1, train)\n",
    "model3.fit(train_data2, padded_sents2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 102
    },
    "colab_type": "code",
    "id": "4PL1sqgBPaVH",
    "outputId": "487a263b-4a75-4332-a108-de58a482300d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Сигануть вся вот зашторишь пути люди много грехов и тут\n",
      "Люлей кто boyfriend не заметно люди могла, вместе все\n",
      "Облик, огней жизни но котором называют сказать проснешься\n",
      "Из со закрывают говоря пола ты мотиватор и на гниёт\n",
      "Мимо, , мы, баронов фанфарон о-о нам спасти\n"
     ]
    }
   ],
   "source": [
    "generate_rap(model1, random_seed = 1212)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 102
    },
    "colab_type": "code",
    "id": "CfGQKTU-PaYT",
    "outputId": "2acdc96c-9ec6-420c-e783-edb29d047941"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Сирано голоса выцветшей и разве металла муках джо интернет три\n",
      "Мечтал лоик wild но и метит мы, втирай гид\n",
      "Отвратительно, отстой захочешь окно летим не сколько пуст\n",
      "Как собака и девки потому ты на инстинктов начинают дворец\n",
      "Моисеев, , набито, бродяг уродливые от не сохраняет\n"
     ]
    }
   ],
   "source": [
    "generate_rap(model2, random_seed = 1212)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 102
    },
    "colab_type": "code",
    "id": "EFZ9ZDCzPabp",
    "outputId": "f2f87716-d008-4b35-b1b9-47797c3ef2af"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Скрываюсь запрете зажить кэш риске нету огригами иконою лучшим терпел\n",
      "Нефть насквозь возрасту пластырь кудахтали неужели одна американская забойным заливаю\n",
      "Эскалатор понят беду порвём костей показан налетай париже следует ребята\n",
      "Махинатор собирательный крыша зря пульта топы орать лучшие падать зомби\n",
      "Обитает swag ае острый time голытьба уважения поможешь пассажирский сопли\n"
     ]
    }
   ],
   "source": [
    "generate_rap(model3, random_seed = 1212)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "yURjFwI7Pael"
   },
   "outputs": [],
   "source": [
    "test_data1,_ = padded_everygram_pipeline(1, test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "9hUVweNwPah0"
   },
   "outputs": [],
   "source": [
    "test_gen1 = []\n",
    "\n",
    "for line in test_data1:\n",
    "  test_gen1.extend(line)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 68
    },
    "colab_type": "code",
    "id": "VP9tyAnpPanE",
    "outputId": "8bb43155-e4cd-4def-9b1f-a573f1b7b519"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Perplexity for unigram MLE model is: inf\n",
      "Perplexity for unigram Laplace model is: 1706.364981704953\n",
      "Perplexity for unigram KneserNeyInterpolated model is: 15534.99999996799\n"
     ]
    }
   ],
   "source": [
    "print('Perplexity for unigram MLE model is: {}'.format(model1.perplexity(test_gen1)))\n",
    "print('Perplexity for unigram Laplace model is: {}'.format(model2.perplexity(test_gen1)))\n",
    "print('Perplexity for unigram KneserNeyInterpolated model is: {}'.format(model3.perplexity(test_gen1)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "cRfFb4mFPawl"
   },
   "outputs": [],
   "source": [
    "model4 = MLE(2)\n",
    "train_data3, padded_sents3 = padded_everygram_pipeline(2, train)\n",
    "model4.fit(train_data3, padded_sents3)\n",
    "\n",
    "model5 = KneserNeyInterpolated(2)\n",
    "train_data4, padded_sents4 = padded_everygram_pipeline(2, train)\n",
    "model5.fit(train_data4, padded_sents4)\n",
    "\n",
    "model6 = Laplace(2)\n",
    "train_data5, padded_sents5 = padded_everygram_pipeline(2, train)\n",
    "model6.fit(train_data5, padded_sents5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 102
    },
    "colab_type": "code",
    "id": "slIOCvZ_P_IJ",
    "outputId": "c1836a82-8466-49ab-8c26-ba17e845a73a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Прогрызает вовне\n",
      "Желе\n",
      "Спазм\n",
      "Воу\n",
      "Звездам\n"
     ]
    }
   ],
   "source": [
    "generate_rap(model4, random_seed = 1212)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "LTZMnPUNb0kh"
   },
   "source": [
    "It is noticeable that we got one word in every string. Probably we can make a conclusion, that sometimes these rappers use so rare words, that probability of contnuation is lower than the probability this word is followed by nothing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 102
    },
    "colab_type": "code",
    "id": "0rf8cEsxP_pa",
    "outputId": "a6a7ac35-2669-4021-efa2-9723e1ab8ec9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Скрывать всё ещё не пушистый\n",
      "Нефтегаз )\n",
      "Эскалатор\n",
      "Мафона и мне всё равно рядом ложусь\n",
      "Обитаем там, но\n"
     ]
    }
   ],
   "source": [
    "generate_rap(model5, random_seed = 1212)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "46nrGvOQXXep"
   },
   "source": [
    "The same as in the previous model: the word нефтегаз or эскалатор are not likely to be followed by anything"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 102
    },
    "colab_type": "code",
    "id": "tiBGgwjkP_nh",
    "outputId": "fbf1fb76-84fe-455d-be33-55dfd53af8d6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Развод, зверь неведомый\n",
      "И не всегда видит бедуин\n",
      "Ярко тут\n",
      "Два скупленных тейпа, разъеби чувака в мире существует вандализм\n",
      "Искусства нико пиросмани\n"
     ]
    }
   ],
   "source": [
    "generate_rap(model6, random_seed = 1212)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ns9xZgDSP_e2"
   },
   "outputs": [],
   "source": [
    "test_data2,_ = padded_everygram_pipeline(2, test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "-rBXhuHdP_dE"
   },
   "outputs": [],
   "source": [
    "test_gen2 = []\n",
    "\n",
    "for line in test_data2:\n",
    "  test_gen2.extend(line)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 68
    },
    "colab_type": "code",
    "id": "C7lgPZQxP_bb",
    "outputId": "6b515748-0bd1-462e-f8f3-764522800c27"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Perplexity for unigram MLE model is: inf\n",
      "Perplexity for unigram KneserNeyInterpolated model is: 4299.172680505865\n",
      "Perplexity for unigram Laplace model is: 1580.3979909430316\n"
     ]
    }
   ],
   "source": [
    "print('Perplexity for unigram MLE model is: {}'.format(model4.perplexity(test_gen2)))\n",
    "print('Perplexity for unigram KneserNeyInterpolated model is: {}'.format(model5.perplexity(test_gen2)))\n",
    "print('Perplexity for unigram Laplace model is: {}'.format(model6.perplexity(test_gen2)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "7_O9t7zLbSk3"
   },
   "source": [
    "Results are prette the same with when we used only Oxxxymiron's texts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "daJvuSYHP_S2"
   },
   "outputs": [],
   "source": [
    "#trigrams\n",
    "model7 = MLE(3)\n",
    "train_data6, padded_sents6 = padded_everygram_pipeline(3, train)\n",
    "model7.fit(train_data6, padded_sents6)\n",
    "\n",
    "model8 = Laplace(3)\n",
    "train_data7, padded_sents7 = padded_everygram_pipeline(3, train)\n",
    "model8.fit(train_data7, padded_sents7)\n",
    "\n",
    "model9 = KneserNeyInterpolated(3)\n",
    "train_data8, padded_sents8 = padded_everygram_pipeline(3, train)\n",
    "model9.fit(train_data8, padded_sents8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 102
    },
    "colab_type": "code",
    "id": "cCXdbUJ0P_RL",
    "outputId": "4f324821-f373-4363-bb48-8a990d814463"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Памяти у всего мира все нигеры поднимают свои руки вверх\n",
      "В никуда\n",
      "Я пишу, это день плохого парня (парня )\n",
      "Оба разобьемся о скалы\n",
      "Видал\n"
     ]
    }
   ],
   "source": [
    "generate_rap(model7, random_seed = 1212)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 102
    },
    "colab_type": "code",
    "id": "V12pGX-oPa8b",
    "outputId": "ee946786-207c-49b1-d4cd-e4c2d960245f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Полемики\n",
      "Голова полна дерьма - черепушка, как блюз\n",
      "Я поздравляю, ты земляк скита и флига, ведь\n",
      "Блядь »\n",
      "Демонстрирует норов, улыбается\n"
     ]
    }
   ],
   "source": [
    "generate_rap(model8, random_seed = 1212)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 102
    },
    "colab_type": "code",
    "id": "hK78DJ7TPa6X",
    "outputId": "2f77f48c-ac8b-437e-a54d-9ea91be05b95"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Скрывать всё, то хит\n",
      "Нефтегаз )\n",
      "Эскалатор\n",
      "Мафона и шахматиста?\n",
      "Обитаем там, где берега кисельные\n"
     ]
    }
   ],
   "source": [
    "generate_rap(model9, random_seed = 1212)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "yUrwGiJuQkH2"
   },
   "outputs": [],
   "source": [
    "test_data3,_ = padded_everygram_pipeline(3, test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "5d5Oi0elQkSc"
   },
   "outputs": [],
   "source": [
    "test_gen3 = []\n",
    "\n",
    "for line in test_data3:\n",
    "  test_gen3.extend(line)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 68
    },
    "colab_type": "code",
    "id": "igl4LlqbPalR",
    "outputId": "76ce3616-7814-4364-dc01-1859faf3e06a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Perplexity for unigram MLE model is: inf\n",
      "Perplexity for unigram Laplace model is: 1115.3910780171748\n",
      "Perplexity for unigram KneserNeyInterpolated model is: 1460.751565342289\n"
     ]
    }
   ],
   "source": [
    "print('Perplexity for unigram MLE model is: {}'.format(model7.perplexity(test_gen3)))\n",
    "print('Perplexity for unigram Laplace model is: {}'.format(model8.perplexity(test_gen3)))\n",
    "print('Perplexity for unigram KneserNeyInterpolated model is: {}'.format(model9.perplexity(test_gen3)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "vTC2Nbp4beJ-"
   },
   "source": [
    "We also can say that when we come to using trigrams, the performance of KneserNeyImplementation is getting closer to one of Laplace smoothing."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "VFI3XFAnb5Ih"
   },
   "source": [
    "Generally, the task was really innteresting as a chance to to see how different models behave on something cool not boring (like rap songs)\n",
    "I would say that it takes very very long to run some models, and very very long to wait for the NN algorithm (taking into consideration that we have to have quite a lot of epochs to train our model well).\n",
    "Even though we can see the lowest perplexity with the Laplace smoothing model (higher performance on the test sample), we should also say, that, firstly, perplexity of KnesserNeyInterpolation becomes lower when we move to longer word orders (from unnigrams to trigrams). And, secondly, perplexity of MLE model is always (in our cases) infinity, but it is executed a way faster and I would't say that the generated rap is any worse than one generated by other models.\n",
    "Finally, it would be interesting to add even more russian rap artist to the list to see the results. But it would take a lot of time and capacities."
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "task2, part2.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
